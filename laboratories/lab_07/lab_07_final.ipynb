{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io.wavfile as spwav\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def min_max_avg(ary: np.array) -> tuple:\n",
    "    \"\"\"\n",
    "    Extract minimum, maximum, and compute the average of the array\n",
    "\n",
    "    Args:\n",
    "        ary (np.array): input array\n",
    "\n",
    "    Returns:\n",
    "        tuple: tuple of (min, max, avg)\n",
    "    \"\"\"\n",
    "    return (np.min(ary), np.max(ary), np.mean(ary))\n",
    "\n",
    "\n",
    "def create_dict_dataset(path:str, is_eval:bool=False) -> tuple:\n",
    "    \"\"\"\n",
    "    function used to read the dataset. It creates a dictionary in\n",
    "    the following form:\n",
    "    id: {label, array, min_max_avg}\n",
    "\n",
    "    Args:\n",
    "        path (str): path used to read the dataset\n",
    "        is_eval (bool, optional): boolean flag to set to True\n",
    "        if the dataset you want to read is the evaluation one.\n",
    "        Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        tuple: dataset in dictionary form, list of arrays' shape (num of samples), list of arrays\n",
    "    \"\"\"\n",
    "    samples = os.listdir(path)\n",
    "    d = dict()\n",
    "    frequency = spwav.read(path + samples[0])[0]\n",
    "    lengths = []\n",
    "    mma_list = [] # min_max_avg list\n",
    "    arys = []\n",
    "    for sample in samples:\n",
    "        if is_eval:\n",
    "            id = int(sample.split('.')[0])\n",
    "        else:\n",
    "            id = int(sample.split('_')[0])\n",
    "        ary = spwav.read(path + sample)[1]\n",
    "        time_length = ary.shape\n",
    "        arys.append(ary)\n",
    "        lengths.append(time_length)\n",
    "        mma_list.append(min_max_avg(ary))\n",
    "        if is_eval:\n",
    "            d_temp = {'ary': ary,\n",
    "                    'min_max_avg':min_max_avg(ary),\n",
    "                    'time': round(time_length[0]/frequency, 2)} # till -4 since it has the .wav extension\n",
    "        else:\n",
    "            d_temp = {'label': int(sample.split('_')[1][:-4]),\n",
    "                    'ary': ary,\n",
    "                    'min_max_avg':min_max_avg(ary),\n",
    "                    'time': round(time_length[0]/frequency, 2)} # till -4 since it has the .wav extension\n",
    "        d[id] = d_temp \n",
    "    return d, lengths, arys\n",
    "\n",
    "def padding(ary: np.array, target_len:int, padding_element:int=0) -> np.array:\n",
    "    \"\"\"\n",
    "    Pad an array with the given length and the given element\n",
    "\n",
    "    Args:\n",
    "        ary (np.array): input array to pad\n",
    "        target_len (int): length to pad the array\n",
    "        padding_element (int, optional): element used to pad. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        np.array: padded array\n",
    "    \"\"\"\n",
    "    return np.pad(ary, (0, target_len), 'constant',  constant_values=padding_element)\n",
    "\n",
    "def pad_arrays(arys:list, max_length:int, value=0,) -> list:\n",
    "    \"\"\"\n",
    "    Function that padd all the arrays to the given max length\n",
    "\n",
    "    Args:\n",
    "        arys (list): list of arrays to pad\n",
    "        max_length (int): target length of the array\n",
    "        value (int, optional): value used to pad. Values can be 'mean' or generic values. Defaults to 0.\n",
    "\n",
    "    Returns:\n",
    "        list: list of padded arrays\n",
    "    \"\"\"\n",
    "    new_arys = []\n",
    "    for a in arys:\n",
    "        width_to_pad = max_length-len(a)\n",
    "                \n",
    "        if value == 'mean':\n",
    "            new_ar = padding(a, width_to_pad, np.mean(a))\n",
    "        else:\n",
    "            new_ar = padding(a, width_to_pad, value)\n",
    "    \n",
    "        new_arys.append(new_ar)\n",
    "    return new_arys\n",
    "\n",
    "## arrivato al punto in cui devo vedere se mettere o meno new_mma_list. \n",
    "# Creare funzione per creare il dataframe.\n",
    "\n",
    "def compute_mma_list(arys:list) -> list:\n",
    "    \"\"\"\n",
    "    Function that will compute min, max, and mean of each array in a given list\n",
    "\n",
    "    Args:\n",
    "        arys (list): list of arrays\n",
    "\n",
    "    Returns:\n",
    "        list: list of tuples of min, max, and average. \n",
    "        One entry for each array in arys\n",
    "    \"\"\"\n",
    "    mma_list = []\n",
    "    for a in arys:\n",
    "        mma_list.append(min_max_avg(a))\n",
    "    return mma_list\n",
    "\n",
    "def create_df(d:dict, arys:list, avg_threshold=-5) -> pd.DataFrame:\n",
    "    mma_list = compute_mma_list(arys)\n",
    "    df = pd.DataFrame.from_dict(d).T\n",
    "    df.ary = arys\n",
    "    df.min_max_avg = mma_list\n",
    "    df.sort_index(axis=0, inplace=True)\n",
    "    avg = []\n",
    "    for tup in df.min_max_avg:\n",
    "        avg.append(tup[-1])\n",
    "    df['avg'] = avg\n",
    "    # noise removal, we remove arrays with mean value below -5. \n",
    "    # I've seen that even if I pad with 0, the overall mean is strongly below -5,\n",
    "    # but I know I should do it in a more general way\n",
    "    mask = df['avg'] > avg_threshold\n",
    "    return df[mask]\n",
    "\n",
    "def simple_moving_average(list_of_arys:list) -> np.array:\n",
    "    list_of_arys = list(list_of_arys)\n",
    "    ary = np.zeros(shape=(len(list_of_arys)))\n",
    "    for id in range(len(list_of_arys)):\n",
    "        num_values = len(list_of_arys[id])\n",
    "        tot = np.sum(list_of_arys[id])\n",
    "        ary[id] = tot/num_values\n",
    "    return ary\n",
    "\n",
    "def cumulative_moving_average(list_of_arys:list) -> np.array:\n",
    "    temp = [(np.sum(i), len(i)) for i in list_of_arys]\n",
    "    mean_variable = 0\n",
    "    values_cnt = 0\n",
    "    out_list = []\n",
    "    \n",
    "    for i in range(len(temp)):\n",
    "        sum, l = temp[i]\n",
    "        if i == 0:\n",
    "            mean_variable = sum/l\n",
    "            values_cnt += l\n",
    "            out_list.append(mean_variable)\n",
    "        else:\n",
    "            mean_variable = (sum + values_cnt*mean_variable)/(l + values_cnt)\n",
    "            values_cnt += l\n",
    "            out_list.append(mean_variable)\n",
    "\n",
    "\n",
    "    return np.array(out_list)\n",
    "\n",
    "def bucket(df:pd.DataFrame, num_buckets:int=100, type_of_feature:str='sma', is_eval:bool=False):\n",
    "    another_dict = dict()\n",
    "\n",
    "    for id, array in zip(df.ary.index, df.ary):\n",
    "        split_ary = np.array_split(array, num_buckets)\n",
    "        cnt_feature = 0\n",
    "        features = dict()\n",
    "        for subary in split_ary:\n",
    "            features[f'feature_{cnt_feature}'] = subary\n",
    "            cnt_feature += 1\n",
    "        another_dict[id] = features\n",
    "    \n",
    "    if type_of_feature == 'sma':\n",
    "        # Simple moving average\n",
    "        sma_dict = {}\n",
    "        for key, item in another_dict.items():\n",
    "            simple_mean = simple_moving_average(item.values())\n",
    "            sma_dict[key] = {f'feature_{i}':m for i,m in enumerate(simple_mean)}\n",
    "        bucket_df = pd.DataFrame.from_dict(sma_dict).T\n",
    "        \n",
    "    elif type_of_feature == 'cma':\n",
    "        # Cumulative moving average\n",
    "        cum_avg_dict = dict()\n",
    "        for key, item in another_dict.items():\n",
    "            mean = cumulative_moving_average(item.values())        \n",
    "            cum_avg_dict[key] = {f'feature_{i}': m for i,m in enumerate(mean)}\n",
    "        bucket_df = pd.DataFrame.from_dict(cum_avg_dict).T\n",
    "    if is_eval: \n",
    "        return bucket_df    \n",
    "    \n",
    "    bucket_df['label'] = df.label\n",
    "    return bucket_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset\n",
    "dev, train_lengths, train_arys = create_dict_dataset('./free_spoken_digit/dev/')\n",
    "dev_max_length = max(train_lengths)[0]\n",
    "\n",
    "# eval dataset\n",
    "eval, eval_lengths, eval_arys = create_dict_dataset('./free_spoken_digit/eval/', is_eval= True)\n",
    "eval_max_length = max(eval_lengths)[0]\n",
    "\n",
    "#check the maximum length between train and eval, to have homogeneous padding\n",
    "if eval_max_length > dev_max_length: \n",
    "    max_length = eval_max_length\n",
    "else:\n",
    "    max_length = dev_max_length\n",
    "    \n",
    "#### train ####\n",
    "train_new_arys = pad_arrays(train_arys, max_length, 0)\n",
    "train_df = create_df(dev, train_new_arys, avg_threshold=-5)\n",
    "bucket_train_df = bucket(train_df, 1000, type_of_feature='sma')\n",
    "\n",
    "#### eval #####\n",
    "eval_new_arys = pad_arrays(eval_arys, eval_max_length, 0) # must be coherent with train!\n",
    "eval_df = create_df(eval, eval_new_arys, avg_threshold=-5)\n",
    "bucket_eval_df = bucket(eval_df, 1000, type_of_feature='sma', is_eval=True) # again, must be coherent with train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_991</th>\n",
       "      <th>feature_992</th>\n",
       "      <th>feature_993</th>\n",
       "      <th>feature_994</th>\n",
       "      <th>feature_995</th>\n",
       "      <th>feature_996</th>\n",
       "      <th>feature_997</th>\n",
       "      <th>feature_998</th>\n",
       "      <th>feature_999</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.894737</td>\n",
       "      <td>-7.157895</td>\n",
       "      <td>10.789474</td>\n",
       "      <td>14.210526</td>\n",
       "      <td>22.473684</td>\n",
       "      <td>-38.421053</td>\n",
       "      <td>2.684211</td>\n",
       "      <td>-50.368421</td>\n",
       "      <td>146.421053</td>\n",
       "      <td>-535.368421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.210526</td>\n",
       "      <td>-0.736842</td>\n",
       "      <td>-1.105263</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>-1.473684</td>\n",
       "      <td>-2.789474</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>-1.105263</td>\n",
       "      <td>-0.578947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.789474</td>\n",
       "      <td>-4.315789</td>\n",
       "      <td>1.842105</td>\n",
       "      <td>-8.578947</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>-5.526316</td>\n",
       "      <td>-2.578947</td>\n",
       "      <td>3.421053</td>\n",
       "      <td>-1.842105</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.894737</td>\n",
       "      <td>17.421053</td>\n",
       "      <td>25.578947</td>\n",
       "      <td>-26.105263</td>\n",
       "      <td>-20.157895</td>\n",
       "      <td>-4.631579</td>\n",
       "      <td>-17.578947</td>\n",
       "      <td>1.684211</td>\n",
       "      <td>6.789474</td>\n",
       "      <td>3.789474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.473684</td>\n",
       "      <td>-42.947368</td>\n",
       "      <td>65.157895</td>\n",
       "      <td>-21.736842</td>\n",
       "      <td>-38.631579</td>\n",
       "      <td>165.526316</td>\n",
       "      <td>-298.631579</td>\n",
       "      <td>158.421053</td>\n",
       "      <td>83.578947</td>\n",
       "      <td>-193.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2  feature_3  feature_4   feature_5  \\\n",
       "0   6.894737  -7.157895  10.789474  14.210526  22.473684  -38.421053   \n",
       "1  -0.210526  -0.736842  -1.105263   0.578947  -1.473684   -2.789474   \n",
       "2   1.789474  -4.315789   1.842105  -8.578947   0.894737   -5.526316   \n",
       "4   0.894737  17.421053  25.578947 -26.105263 -20.157895   -4.631579   \n",
       "6   9.473684 -42.947368  65.157895 -21.736842 -38.631579  165.526316   \n",
       "\n",
       "    feature_6   feature_7   feature_8   feature_9  ...  feature_991  \\\n",
       "0    2.684211  -50.368421  146.421053 -535.368421  ...          0.0   \n",
       "1    2.000000   -0.473684   -1.105263   -0.578947  ...          0.0   \n",
       "2   -2.578947    3.421053   -1.842105    0.315789  ...          0.0   \n",
       "4  -17.578947    1.684211    6.789474    3.789474  ...          0.0   \n",
       "6 -298.631579  158.421053   83.578947 -193.052632  ...          0.0   \n",
       "\n",
       "   feature_992  feature_993  feature_994  feature_995  feature_996  \\\n",
       "0          0.0          0.0          0.0          0.0          0.0   \n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "6          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_997  feature_998  feature_999  label  \n",
       "0          0.0          0.0          0.0      4  \n",
       "1          0.0          0.0          0.0      7  \n",
       "2          0.0          0.0          0.0      5  \n",
       "4          0.0          0.0          0.0      3  \n",
       "6          0.0          0.0          0.0      1  \n",
       "\n",
       "[5 rows x 1001 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_0</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_990</th>\n",
       "      <th>feature_991</th>\n",
       "      <th>feature_992</th>\n",
       "      <th>feature_993</th>\n",
       "      <th>feature_994</th>\n",
       "      <th>feature_995</th>\n",
       "      <th>feature_996</th>\n",
       "      <th>feature_997</th>\n",
       "      <th>feature_998</th>\n",
       "      <th>feature_999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.736842</td>\n",
       "      <td>-48.631579</td>\n",
       "      <td>50.368421</td>\n",
       "      <td>24.789474</td>\n",
       "      <td>-130.736842</td>\n",
       "      <td>154.052632</td>\n",
       "      <td>-31.157895</td>\n",
       "      <td>-123.105263</td>\n",
       "      <td>150.578947</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.526316</td>\n",
       "      <td>-10.210526</td>\n",
       "      <td>-16.947368</td>\n",
       "      <td>137.947368</td>\n",
       "      <td>-97.210526</td>\n",
       "      <td>16.157895</td>\n",
       "      <td>-28.736842</td>\n",
       "      <td>-7.526316</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>21.315789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.105263</td>\n",
       "      <td>6.631579</td>\n",
       "      <td>-13.842105</td>\n",
       "      <td>1.368421</td>\n",
       "      <td>14.526316</td>\n",
       "      <td>-7.736842</td>\n",
       "      <td>-24.315789</td>\n",
       "      <td>32.526316</td>\n",
       "      <td>-0.473684</td>\n",
       "      <td>-31.263158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.421053</td>\n",
       "      <td>-1.421053</td>\n",
       "      <td>2.157895</td>\n",
       "      <td>-3.842105</td>\n",
       "      <td>-0.368421</td>\n",
       "      <td>-1.578947</td>\n",
       "      <td>-1.157895</td>\n",
       "      <td>-4.578947</td>\n",
       "      <td>3.894737</td>\n",
       "      <td>-0.631579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.526316</td>\n",
       "      <td>-6.947368</td>\n",
       "      <td>-15.947368</td>\n",
       "      <td>25.947368</td>\n",
       "      <td>-5.473684</td>\n",
       "      <td>-20.526316</td>\n",
       "      <td>150.157895</td>\n",
       "      <td>79.736842</td>\n",
       "      <td>-262.894737</td>\n",
       "      <td>114.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_0  feature_1  feature_2   feature_3   feature_4   feature_5  \\\n",
       "1   9.736842 -48.631579  50.368421   24.789474 -130.736842  154.052632   \n",
       "2  -1.526316 -10.210526 -16.947368  137.947368  -97.210526   16.157895   \n",
       "3   6.105263   6.631579 -13.842105    1.368421   14.526316   -7.736842   \n",
       "4   1.421053  -1.421053   2.157895   -3.842105   -0.368421   -1.578947   \n",
       "5   9.526316  -6.947368 -15.947368   25.947368   -5.473684  -20.526316   \n",
       "\n",
       "    feature_6   feature_7   feature_8   feature_9  ...  feature_990  \\\n",
       "1  -31.157895 -123.105263  150.578947   -2.000000  ...          0.0   \n",
       "2  -28.736842   -7.526316  -10.000000   21.315789  ...          0.0   \n",
       "3  -24.315789   32.526316   -0.473684  -31.263158  ...          0.0   \n",
       "4   -1.157895   -4.578947    3.894737   -0.631579  ...          0.0   \n",
       "5  150.157895   79.736842 -262.894737  114.736842  ...          0.0   \n",
       "\n",
       "   feature_991  feature_992  feature_993  feature_994  feature_995  \\\n",
       "1          0.0          0.0          0.0          0.0          0.0   \n",
       "2          0.0          0.0          0.0          0.0          0.0   \n",
       "3          0.0          0.0          0.0          0.0          0.0   \n",
       "4          0.0          0.0          0.0          0.0          0.0   \n",
       "5          0.0          0.0          0.0          0.0          0.0   \n",
       "\n",
       "   feature_996  feature_997  feature_998  feature_999  \n",
       "1          0.0          0.0          0.0          0.0  \n",
       "2          0.0          0.0          0.0          0.0  \n",
       "3          0.0          0.0          0.0          0.0  \n",
       "4          0.0          0.0          0.0          0.0  \n",
       "5          0.0          0.0          0.0          0.0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers\n",
    "We will use macro F1 score as metric. The F1 score is:\n",
    "$$F1_{score} = 2\\cdot\\frac{Precision\\cdot Recall}{Precision + Recall}$$\n",
    "where\n",
    "$$Precision = \\frac{TP}{TP + FP}$$\n",
    "$$Recall = \\frac{TP}{TP + FN}$$\n",
    "\n",
    "Worst value of F1 score is 0, while the best one is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "np.random.seed(0) #to make experiments reproducible\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(bucket_train_df[bucket_train_df.columns[:-1]], bucket_train_df[bucket_train_df.columns[-1]], test_size=.2)\n",
    "\n",
    "y_train = y_train.astype('int')\n",
    "y_test = y_test.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20931129986500788"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "preds = clf.predict(X_test)\n",
    "f1_score(y_test, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39850737721475016"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, max_features='sqrt', max_depth=30).fit(X_train, y_train)\n",
    "preds = rf.predict(X_test)\n",
    "f1_score(y_test, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15383813941560903"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=7).fit(X_train, y_train)\n",
    "preds = knn.predict(X_test)\n",
    "f1_score(y_test, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1543745991823065"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler().fit(X_train)\n",
    "#X_train = scaler.transform(X_train)\n",
    "gnb = GaussianNB().fit(X_train, y_train)\n",
    "preds = gnb.predict(X_test)\n",
    "f1_score(y_test, preds, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15765029059521102"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "svm_clf = make_pipeline(StandardScaler(), NuSVC(degree=1))\n",
    "svm_clf.fit(X_train, y_train)\n",
    "preds = svm_clf.predict(X_test)\n",
    "f1_score(y_test, preds, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12737773985155904"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural Network, MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(max_iter=300).fit(X_train, y_train)\n",
    "preds = mlp.predict(X_test)\n",
    "f1_score(y_test, preds, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, results are not satisfactory. We should think to another kind of processing. We should think of frequency domain processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy import signal\n",
    "signal.spectrogram()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afad3e5d60d609398ecce3ba468213674dfc27eda2bcdfe27a1dfdc5eca24277"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
