{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab_04: K-NN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-22 15:52:19--  https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4551 (4,4K) [application/x-httpd-php]\n",
      "Saving to: ‘iris.csv’\n",
      "\n",
      "iris.csv            100%[===================>]   4,44K  --.-KB/s    in 0s      \n",
      "\n",
      "2022-04-22 15:52:20 (39,5 MB/s) - ‘iris.csv’ saved [4551/4551]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data -O iris.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-22 15:52:21--  https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/mnist_test.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18289443 (17M) [text/plain]\n",
      "Saving to: ‘mnist.csv’\n",
      "\n",
      "mnist.csv           100%[===================>]  17,44M  29,1MB/s    in 0,6s    \n",
      "\n",
      "2022-04-22 15:52:22 (29,1 MB/s) - ‘mnist.csv’ saved [18289443/18289443]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/dbdmg/data-science-lab/master/datasets/mnist_test.csv -O mnist.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "iris = pd.read_csv('iris.csv', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the seed to obtain same results\n",
    "np.random.seed(42) \n",
    "# set the size of the Test set as the 20% of the dataset\n",
    "size = round(.2*len(iris))\n",
    "# create a mask to retrieve selected rows. \n",
    "# I used choice since I don't want replacements. \n",
    "# I passed the column index and then sampled indexes\n",
    "mask = sorted(np.random.choice(iris.index, size=size, replace=False))\n",
    "X_test, y_test = iris.iloc[mask][names[:-1]], iris.iloc[mask][names[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train mask subtracting indexes belonging to previous mask.\n",
    "# Then we need to cast it to list otherwise .iloc won't work\n",
    "train_mask = list(set(iris.index) - set(mask))\n",
    "X_train, y_train = iris.iloc[train_mask][names[:-1]], iris.iloc[train_mask][names[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearestNeighbors:\n",
    "    def __init__(self, k, distance_metric=\"euclidean\", weighting_scheme:str='uniform'):\n",
    "        self.k = k\n",
    "        self.distance_metric = distance_metric\n",
    "        self.weighting_scheme = weighting_scheme\n",
    "        \n",
    "    def compute_distance(self, x:np.array, y:np.array, type:str='euclidean'):\n",
    "        if type == 'euclidean':\n",
    "            return np.sqrt(np.sum((x-y)**2))\n",
    "        elif type == 'cosine':\n",
    "            num = np.sum(x*y)\n",
    "            den = np.sqrt(np.sum(x**2))*np.sqrt(np.sum(y**2))\n",
    "            return 1 - np.abs(num/den)\n",
    "        elif type == 'manhattan':\n",
    "            return np.sum(np.abs(x-y))\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Store the 'prior knowledge'of you model that will be used\n",
    "        to predict new labels.\n",
    "        :param X : input data points, ndarray, shape = (R,C).\n",
    "        :param y : input labels, ndarray, shape = (R,).\n",
    "        \"\"\"\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        self.classes = list(y.unique()) # retrieve list of classes\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Run the KNN classification on X.\n",
    "        :param X: input data points, ndarray, shape = (N,C).\n",
    "        :return: labels : ndarray, shape = (N,).\n",
    "        \"\"\"\n",
    "        distances = dict() # len = y_test\n",
    "        idx = 0\n",
    "        for test_row in X.values:\n",
    "            dist_list = []\n",
    "            for train_row in self.X_train.values:\n",
    "                dist_list.append(self.compute_distance(test_row, train_row, self.distance_metric))\n",
    "            distances[idx] = np.array(dist_list)\n",
    "            idx += 1\n",
    "\n",
    "        pred = np.zeros(shape=(len(X), len(self.classes)))\n",
    "\n",
    "        # use this stratagem to select indexes where the value is lower than this threshold \n",
    "        for i in range(len(distances)):\n",
    "            threshold = sorted(distances[i])[self.k]\n",
    "            maskerina = np.argwhere(distances[i] < threshold)\n",
    "            for idx in maskerina.flatten():\n",
    "                label = y_train.iloc[idx]\n",
    "                if self.weighting_scheme == 'distance':\n",
    "                    if distances[i][idx] == 0:\n",
    "                        pred[i][label] = np.inf\n",
    "                    else:\n",
    "                        pred[i][label] += 1/(distances[i][idx])\n",
    "                else:\n",
    "                    pred[i][label] += 1\n",
    "        return np.argmax(pred, axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain names of classes\n",
    "classes = iris['class'].unique()\n",
    "\n",
    "# map classes to values 0, 1, 2 used to index when we count the votes\n",
    "classes_dict = {cl:i for i,cl in enumerate(classes)}\n",
    "# reverse_classes to map back names of classes\n",
    "reverse_classes_dict = {i:cl for i,cl in enumerate(classes)}\n",
    "# map classes values (both test and train)\n",
    "y_train = y_train.map(classes_dict)\n",
    "y_test = y_test.map(classes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearestNeighbors(7, 'euclidean', 'distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "predictions = knn.predict(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Iris-setosa\n",
       "1         Iris-setosa\n",
       "2         Iris-setosa\n",
       "3         Iris-setosa\n",
       "4         Iris-setosa\n",
       "5         Iris-setosa\n",
       "6         Iris-setosa\n",
       "7         Iris-setosa\n",
       "8         Iris-setosa\n",
       "9         Iris-setosa\n",
       "10    Iris-versicolor\n",
       "11    Iris-versicolor\n",
       "12    Iris-versicolor\n",
       "13    Iris-versicolor\n",
       "14    Iris-versicolor\n",
       "15    Iris-versicolor\n",
       "16    Iris-versicolor\n",
       "17    Iris-versicolor\n",
       "18    Iris-versicolor\n",
       "19     Iris-virginica\n",
       "20     Iris-virginica\n",
       "21     Iris-virginica\n",
       "22     Iris-virginica\n",
       "23     Iris-virginica\n",
       "24     Iris-virginica\n",
       "25     Iris-virginica\n",
       "26     Iris-virginica\n",
       "27     Iris-virginica\n",
       "28     Iris-virginica\n",
       "29     Iris-virginica\n",
       "dtype: object"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map each integer value to the initial class\n",
    "labeled_classes = pd.Series(predictions).map(reverse_classes_dict)\n",
    "labeled_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(pred:np.array, y_test:np.array) -> float:\n",
    "    accuracy = 0\n",
    "\n",
    "    for i,j in zip(pred, y_test):\n",
    "        if i == j:\n",
    "            accuracy += 1\n",
    "        else:\n",
    "            continue\n",
    "    return accuracy/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_accuracy(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(X_train:np.array, y_train:np.array, X_test:np.array, y_test:np.array, k_list:list, distance_names:list, schemes:list) -> dict:\n",
    "    results = dict()\n",
    "    for k in k_list:\n",
    "        print(f'{k}-Nearest neighbors...')\n",
    "        scheme_list = []\n",
    "        \n",
    "        # choose weighting scheme\n",
    "        for scheme in schemes:\n",
    "            #print(f'\\tUsing {scheme} scheme...')\n",
    "            res_list = []\n",
    "            \n",
    "            # compute each distance\n",
    "            for distance in distance_names:    \n",
    "                #print(f'\\tUsing {distance} as distance metric')\n",
    "                \n",
    "                knn = KNearestNeighbors(k, distance, scheme)\n",
    "                knn.fit(X_train, y_train)\n",
    "            \n",
    "                predictions = knn.predict(X_test)\n",
    "            \n",
    "                accuracy = compute_accuracy(predictions, y_test)\n",
    "            \n",
    "                # save the result of each distance in a list of tuple\n",
    "                res_list.append((distance, accuracy))\n",
    "            \n",
    "            # save each res_list as value of scheme\n",
    "            scheme_list.append({f'{scheme}_weighting':res_list})\n",
    "            \n",
    "        # end up with a dictionary with k as initial field and as value\n",
    "        # a list containing 2 dictionaries. Each of them contains the weighting and\n",
    "        # corresponding distances and accuracies.\n",
    "        results[k] = scheme_list\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Nearest neighbors...\n",
      "2-Nearest neighbors...\n",
      "3-Nearest neighbors...\n",
      "4-Nearest neighbors...\n",
      "5-Nearest neighbors...\n",
      "7-Nearest neighbors...\n",
      "10-Nearest neighbors...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: [{'uniform_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9),\n",
       "    ('manhattan', 0.9666666666666667)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9),\n",
       "    ('manhattan', 0.9666666666666667)]}],\n",
       " 2: [{'uniform_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9666666666666667),\n",
       "    ('manhattan', 1.0)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9666666666666667),\n",
       "    ('manhattan', 1.0)]}],\n",
       " 3: [{'uniform_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9666666666666667),\n",
       "    ('manhattan', 1.0)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9666666666666667),\n",
       "    ('manhattan', 1.0)]}],\n",
       " 4: [{'uniform_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9666666666666667),\n",
       "    ('manhattan', 1.0)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 0.9666666666666667),\n",
       "    ('manhattan', 1.0)]}],\n",
       " 5: [{'uniform_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 1.0),\n",
       "    ('manhattan', 1.0)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 1.0),\n",
       "    ('manhattan', 1.0)]}],\n",
       " 7: [{'uniform_weighting': [('euclidean', 0.9666666666666667),\n",
       "    ('cosine', 1.0),\n",
       "    ('manhattan', 1.0)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 1.0),\n",
       "    ('manhattan', 1.0)]}],\n",
       " 10: [{'uniform_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 1.0),\n",
       "    ('manhattan', 0.9666666666666667)]},\n",
       "  {'distance_weighting': [('euclidean', 1.0),\n",
       "    ('cosine', 1.0),\n",
       "    ('manhattan', 1.0)]}]}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_list = [1,2,3,4,5,7,10]\n",
    "distance_names = ['euclidean', 'cosine', \"manhattan\"]\n",
    "schemes = ['uniform', 'distance']\n",
    "res = run_knn(X_train, y_train, X_test, y_test, k_list, distance_names, schemes)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = pd.read_csv('mnist.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('mnist.csv', \"r\") as f:\n",
    "    labels = [] \n",
    "    images = []\n",
    "    for cols in csv.reader(f):\n",
    "        labels.append(cols[0])\n",
    "        images.append(cols[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.array(labels, dtype=int)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of arrays\n",
    "images = [np.array(i, dtype=int) for i in images]\n",
    "# array of arrays\n",
    "images = np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 980\n",
      "1 1135\n",
      "2 1032\n",
      "3 1010\n",
      "4 982\n",
      "5 892\n",
      "6 958\n",
      "7 1028\n",
      "8 974\n",
      "9 1009\n"
     ]
    }
   ],
   "source": [
    "# check how many images for each number we have\n",
    "numbers = list(range(10))\n",
    "for n in numbers:\n",
    "    print(n, sum(labels == n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = []\n",
    "numbers = list(range(10)) # 0, 1, ..., 9\n",
    "\n",
    "for n in numbers:\n",
    "    a = np.argwhere(labels == n).flatten()\n",
    "    sample = np.random.choice(a, size=100)\n",
    "    indexes.append(sample)\n",
    "indexes = np.array(indexes).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  775  776  777  778  779  780  781  782  \\\n",
       "0  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "4  0  0  0  0  0  0  0  0  0  0  ...    0    0    0    0    0    0    0    0   \n",
       "\n",
       "   783  label  \n",
       "0    0      0  \n",
       "1    0      0  \n",
       "2    0      0  \n",
       "3    0      0  \n",
       "4    0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_df = pd.DataFrame(images[indexes])\n",
    "mnist_df['label'] = labels[indexes]\n",
    "mnist_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "size = round(.2*len(mnist_df))\n",
    "test_mask = sorted(np.random.choice(mnist_df.index, size=size, replace=False))\n",
    "X_test, y_test = mnist_df.iloc[test_mask][mnist_df.columns[:-1]], mnist_df.iloc[test_mask][mnist_df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0      0\n",
       " 1      0\n",
       " 2      0\n",
       " 3      0\n",
       " 4      0\n",
       "       ..\n",
       " 779    0\n",
       " 780    0\n",
       " 781    0\n",
       " 782    0\n",
       " 783    0\n",
       " Name: 10, Length: 784, dtype: int64,\n",
       " 0)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0], y_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = list(set(mnist_df.index) - set(test_mask))\n",
    "X_train, y_train = mnist_df.iloc[train_mask][mnist_df.columns[:-1]], mnist_df.iloc[train_mask][mnist_df.columns[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.925"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_mnist = KNearestNeighbors(4, 'euclidean', 'distance')\n",
    "knn_mnist.fit(X_train, y_train)\n",
    "pred = knn_mnist.predict(X_test)\n",
    "compute_accuracy(pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-Nearest neighbors...\n",
      "2-Nearest neighbors...\n",
      "3-Nearest neighbors...\n",
      "4-Nearest neighbors...\n",
      "5-Nearest neighbors...\n",
      "7-Nearest neighbors...\n",
      "10-Nearest neighbors...\n"
     ]
    }
   ],
   "source": [
    "k_list = [1,2,3,4,5,7,10]\n",
    "distance_names = ['euclidean', 'cosine', \"manhattan\"]\n",
    "schemes = ['uniform', 'distance']\n",
    "results = run_knn(X_train, y_train, X_test, y_test, k_list, distance_names, schemes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_results = dict()\n",
    "for k,v in results.items():\n",
    "    uniform = sorted(v[0]['uniform_weighting'])[0]\n",
    "    distance = sorted(v[1]['distance_weighting'])[0]\n",
    "    if uniform[1] > distance[1]:\n",
    "        #print('uniform')\n",
    "        #print(k, uniform)\n",
    "        best_results[k] = ('uniform_weighting', *uniform) # unpack the tuple\n",
    "    elif uniform[1] == distance[1]:\n",
    "        #print('They are the same')\n",
    "        best_results[k] = ('uniform_weighting', *uniform)\n",
    "    else: \n",
    "        #print(\"distance\")\n",
    "        #print(k, distance)\n",
    "        best_results[k] = ('distance_weighting', *distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: ('uniform_weighting', 'cosine', 0.9),\n",
       " 2: ('distance_weighting', 'cosine', 0.89),\n",
       " 3: ('uniform_weighting', 'cosine', 0.92),\n",
       " 4: ('uniform_weighting', 'cosine', 0.92),\n",
       " 5: ('uniform_weighting', 'cosine', 0.92),\n",
       " 7: ('uniform_weighting', 'cosine', 0.92),\n",
       " 10: ('uniform_weighting', 'cosine', 0.915)}"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afad3e5d60d609398ecce3ba468213674dfc27eda2bcdfe27a1dfdc5eca24277"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('data_science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
